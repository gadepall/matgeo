\let\negmedspace\undefined
\let\negthickspace\undefined
\documentclass[journal]{IEEEtran}
\usepackage[a4paper, margin=10mm, onecolumn]{geometry}
%\usepackage{lmodern} % Ensure lmodern is loaded for pdflatex
\usepackage{tfrupee} % Include tfrupee package

\setlength{\headheight}{1cm} % Set the height of the header box
\setlength{\headsep}{0mm}     % Set the distance between the header box and the top of the text

\usepackage{gvv-book}
\usepackage{gvv}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{txfonts}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{gensymb}
\usepackage{comment}
\usepackage[breaklinks=true]{hyperref}
\usepackage{tkz-euclide} 
\usepackage{listings}
% \usepackage{gvv}                                        
\def\inputGnumericTable{}                                 
\usepackage[latin1]{inputenc}                                
\usepackage{color}                                            
\usepackage{array}                                            
\usepackage{longtable}                                       
\usepackage{calc}                                             
\usepackage{multirow}                                         
\usepackage{hhline}                                           
\usepackage{ifthen}                                           
\usepackage{lscape}
\usepackage{tikz}
\usetikzlibrary{patterns}

\begin{document}


\bibliographystyle{IEEEtran}
\vspace{3cm}


\numberwithin{equation}{enumi}
\numberwithin{figure}{enumi}
\renewcommand{\thetable}{\theenumi}


% Marks the beginning of the document

\bibliographystyle{IEEEtran}
\vspace{3cm}


\title{GATE ASSIGNMENT-2}
\author{AI25BTECH11004-B.JASWANTH}
% \maketitle
% \newpage
% \bigskip
{\let\newpage\relax\maketitle}


\renewcommand{\thefigure}{\theenumi}
\renewcommand{\thetable}{\theenumi}
\setlength{\intextsep}{10pt} % Space between text and floats

\section*{General Aptitude (GA)}

\begin{enumerate}

 

\item The fishermen, \rule{2cm}{0.1pt} the flood victims  owed their lives, were rewarded by the government.\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item whom
    \item to which
    \item to whom
    \item that
\end{enumerate}
\end{multicols}

\item Some students were not involved in the strike.
\\
If the above statement is true, which of the following conclusions is/are logically necessary? \hfill(GATE ST 2019)

(1) Some who were involved in the strike were students.\\
(2) No student was involved in the strike.\\
(3) At least one student was involved in the strike.\\
(4) Some who were not involved in the strike were students.

\begin{multicols}{4}
  \begin{enumerate}
    \item 1 and 2 \hspace{1cm}
    \item 3 \hspace{1cm}
    \item4 \hspace{1cm}
    \item 2 and 3
\end{enumerate}
\end{multicols}

\item The radius as well as the height of a circular cone increases by 10\%. The percentage increase in its volume is \rule{2cm}{0.1pt}. \\
\hspace*{15.7cm}(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item 17.1
    \item 21.0
    \item 33.1
    \item 72.8
\end{enumerate}
\end{multicols}

\item Five numbers 10, 7, 5, 4 and 2 are to be arranged in a sequence from left to right following the directions given below:\\
\hspace*{15.7cm}(GATE ST 2019)
1. No two odd or even numbers are next to each other.\\
2. The second number from the left is exactly half of the left-most number.\\
3. The middle number is exactly twice the right-most number.\\
Which is the second number from the right?
\begin{multicols}{4}
\begin{enumerate}
    \item 2 
    \item 4 
    \item 7 
    \item 10 
\end{enumerate}
\end{multicols}

\item Until Iran came along, India had never been \rule{2cm}{0.1pt} in kabaddi.\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item defeated
    \item defeating
    \item defeat
    \item defeatist
\end{enumerate}
\end{multicols}

\item Since the last one year, after a 125 basis point reduction in repo rate by the Reserve Bank of India, banking institutions have been making a demand to reduce interest rates on small saving schemes. Finally, the government announced yesterday a reduction in interest rates on small saving schemes to bring them on par with fixed deposit interest rates.\\
Which one of the following statements can be inferred from the given passage?\hfill(GATE ST 2019)
\begin{enumerate}
    \item Whenever the Reserve Bank of India reduces the repo rate, the interest rates on small saving schemes are also reduced 
    \item Interest rates on small saving schemes are always maintained on par with fixed deposit interest rates 
    \item The government sometimes takes into consideration the demands of banking institutions before reducing the interest rates on small saving schemes 
    \item A reduction in interest rates on small saving schemes follow only after a reduction in repo rate by the Reserve Bank of India 
\end{enumerate}

\item In a country of 1400 million population, 70\% own mobile phones. Among the mobile phone owners, only 294 million access the Internet. Among these Internet users, only half buy goods from e-commerce portals. What is the percentage of these buyers in the country?\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item 10.50
    \item 14.70
    \item 15.00
    \item 50.00
\end{enumerate}
\end{multicols}

\item The nomenclature of Hindustani music has changed over the centuries. Since the medieval period dhrupad styles were identified as baanis. Terms like gayaki and baaj were used to refer to vocal and instrumental styles, respectively. With the institutionalization of music education the term gharana became acceptable. Gharana originally referred to hereditary musicians from a particular lineage, including disciples and grand disciples. \\
Which one of the following pairings is NOT correct?\hfill(GATE ST 2019)
\begin{enumerate}
    \item dhrupad, baani 
    \item gayaki, vocal 
    \item baaj, institution 
    \item gharana, lineage 
\end{enumerate}

\item Two trains started at 7AM from the same point. The first train travelled north at a speed of 80 km/h and the second train travelled south at a speed of 100 km/h. The time at which they were 540 km apart is \rule{2cm}{0.1pt} AM.\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item 9
    \item 10
    \item 11
    \item 11.30
\end{enumerate}
\end{multicols}

\item ``I read somewhere that in ancient times the prestige of a kingdom depended upon the number of taxes that it was able to levy on its people. It was very much like the prestige of a head-hunter in his own community.''\\
Based on the paragraph above, the prestige of a head-hunter depended upon \rule{2cm}{0.1pt}\hfill(GATE ST 2019)
\begin{enumerate}
    \item the prestige of the kingdom  
    \item the prestige of the heads 
    \item the number of taxes he could levy 
    \item the number of heads he could gather 
\end{enumerate}
\end{enumerate}

\begin{enumerate}[start=1]
    \item Evaluate  \(\lim_{n \to \infty} \sum_{k=1}^{n} \frac{n}{n^2 + k^2}\)\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item \( \frac{e}{3} \)
    \item \( \frac{5}{6} \)
    \item \( \frac{3}{4} \)
    \item \( \frac{\pi}{4} \)
\end{enumerate}
\end{multicols}

\item Let \( \vec{F} = (x - y + z)(\hat{i} + \hat{j}) \) be a vector field on \( \mathbb{R}^3 \). The line integral \( \int_{\vec{C}} \vec{F} \cdot d\vec{r} \), where \( C \) is the triangle with vertices (0,0,0), (5,0,0) and (5,5,0) traversed in that order is  \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item -25 
    \item 25 
    \item 50   
    \item 5 
\end{enumerate}
\end{multicols}

\item Let \(\{1,2,3,4\}\) represent the outcomes of a random experiment, and \(P(\{1\}) = P(\{2\}) = P(\{3\}) = P(\{4\}) = 1/4\). Suppose that \(A_1 = \{1,2\}, A_2 = \{2,3\},  A_3 = \{3,4\}, A_4 = \{1,2,3\}\).
Which of the following statements is true?\hfill(GATE ST 2019)
\begin{enumerate}
    \item \(A_1\) and \(A_2\) are not independent. 
    \item \(A_3\) and \(A_4\) are independent. 
    \item \(A_1\) and \(A_4\) are not independent. 
    \item \(A_2\) and \(A_4\) are independent. 
\end{enumerate}

\item A fair die is rolled two times independently. Given that the outcome on the first roll is 1, the expected value of the sum of the two outcomes is \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item 4
    \item 4.5
    \item 3
    \item 5.5
\end{enumerate}
\end{multicols}

\item The dimension of the vector space of \(7 \times 7\) real symmetric matrices with trace zero and the sum of the off-diagonal elements zero is \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
    \item 47
    \item 28
    \item 27
    \item 26
\end{enumerate}
\end{multicols}



\item Let \(A\) be a \(6 \times 6\) complex matrix with \(A^3 \neq 0\) and \(A^4 = 0\). Then the number of Jordan blocks of \(A\) is:\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
     \item 1 or 6
     \item 2 or 3
     \item 4
     \item 5
\end{enumerate}
\end{multicols}

\item Let \(X_1, \ldots, X_n\) be a random sample from a uniform distribution defined over \((0, \theta)\), where \(\theta > 0\) and \(n \geq 2\). Let \(X_{(1)} = \min\{X_1,\ldots,X_n\}\) and \(X_{(n)} = \max\{X_1, \ldots, X_n\}\). Then the covariance between \(X_{(n)}\) and \(\frac{X_{(1)}}{X_{(n)}}\) is:\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item 0
\item \(n(n+1) \theta\)
\item \(n \theta\)
\item \(n^2 (n+1) \theta\)
\end{enumerate}
\end{multicols}

\item Let \(X_1, \ldots, X_n\) be a random sample drawn from a population with probability density function \(f(x; \theta) = \theta x^{\theta - 1}, \, 0 \leq x \leq 1, \theta > 0\). Then the maximum likelihood estimator of \(\theta\) is:\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(- \frac{n}{\sum_{i=1}^n \log X_i}\)
\item \(- \frac{\sum_{i=1}^n \log X_i}{n}\)
\item \(\left(\prod_{i=1}^n X_i \right)^{1/n}\)
\item \(\frac{\prod_{i=1}^n X_i}{n}\)
\end{enumerate}
\end{multicols}

\item Let \(Y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \epsilon_i, i = 1, \ldots, 10\), where \(x_{1i}\)'s and \(x_{2i}\)'s are fixed covariates and \(\epsilon_i\)'s are uncorrelated random variables with mean 0 and unknown variance \(\sigma^2\). Here \(\beta_0, \beta_1, \beta_2\) are unknown parameters. Further,define \(\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_{1i} + \hat{\beta}_2 x_{2i}\), where \(\hat{\beta}_0, \hat{\beta}_1, \hat{\beta}_2\) are unbiased least squares estimators of \(\beta_0, \beta_1, \beta_2\). Then an unbiased estimator of \(\sigma^2\) is:\hfill(GATE ST 2019)
\begin{multicols}{2}
\begin{enumerate}
\item \(\frac{\sum_{i=1}^{10} (Y_i - \hat{Y}_i)^2}{10}\)
\item \(\frac{\sum_{i=1}^{10} (Y_i - \hat{Y}_i)^2}{7}\)
\item \(\frac{\sum_{i=1}^{10} (Y_i - \hat{Y}_i)^2}{8}\)
\item \(\frac{\sum_{i=1}^{10} (Y_i - \hat{Y}_i)^2}{9}\)
\end{enumerate}
\end{multicols}

\item For \(i = 1, 2, 3\), let \(Y_i = \alpha + \beta x_i + \epsilon_i\), where \(x_i\) are fixed covariates and \(\epsilon_i\) are independent and identically distributed standard normal random variables. Here \(\alpha\) and \(\beta\) are unknown parameters. Given the observation \\
\begin{tabular}{|c|c|c|c|}
\hline
$Y_i$ & 0.5 & 2.5 & 0.5 \\
\hline
$x_i$ & 1   & 1   & -2  \\
\hline
\end{tabular}\\
The best linear unbiased estimate of \(\alpha + \beta\) is equal to: \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item 1.5
\item 1
\item 1.8
\item 2.1
\end{enumerate}
\end{multicols}

\item Consider a discrete time Markov chain on the state space \(\{1,2,3\}\) with one-step transition probability matrix
P = \myvec{
0.7 & 0.3 & 0 \\
0 & 0.6 & 0.4 \\
0 & 0 & 1}.
Which of the following statements is true?\hfill(GATE ST 2019)
\begin{enumerate}
\item States 1, 3 are recurrent and state 2 is transient.
\item State 3 is recurrent and states 1, 2 are transient.
\item States 1, 2, 3 are recurrent.
\item States 1, 2 are recurrent and state 3 is transient.
\end{enumerate}

\item The minimal polynomial of the matrix
\myvec{1 & 1 & 2 & 0 \\
0 & 2 & 1 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 2}
is:\hfill(GATE ST 2019)
\begin{enumerate}
\item \((x - 1)(x - 2)\)
\item \((x - 1)^2 (x - 2)\)
\item \((x - 1)(x - 2)^2\)
\item \((x - 1)^2 (x - 2)^2\)
\end{enumerate}

\item Let \((X_1, X_2, X_3)\) be a trivariate normal random vector with mean vector \((-3, 1, 4)\) and variance-covariance matrix
\begin{align*}
\myvec{4 & 0 & 0 \\
0 & 3 & -3 \\
0 & -3 & 4}.
\end{align*}

Which of the following statements are true? \hfill(GATE ST 2019) \\
(1) \(X_2\) and \(X_3\) are independent.\\
(2) \(X_1 + X_3\) and \(X_2\) are independent.\\
(3) \((X_2, X_3)\) and \(X_1\) are independent.\\
(4) \(\frac{1}{2}(X_2 + X_3)\) and \(X_1\) are independent.
\begin{multicols}{2}
\begin{enumerate}
    \item (1) and (3)
    \item (2) and (3)
    \item (1) and (4)
    \item (3) and (4)
\end{enumerate}
\end{multicols}

\item A \(2^3\) factorial experiment with factors \(A, B, C\) is arranged in two blocks of four plots each as follows: (Below (1) denotes the treatment in which \(A, B, C\) are at the lower level, \(ac\) denotes treatment in which \(A\) and \(C\) are at the higher level and \(B\) is at the lower level, and so on.)

\begin{tabular}{|c|c|c|c|c|}
\hline
Block 1 & (1) & ab & ac & bc \\
\hline
Block 2 & a & b  & c & abc \\
\hline
\end{tabular}\\

The treatment contrast that is confounded with the blocks is:\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(BC\)
\item \(AC\)
\item \(AB\)
\item \(ABC\)
\end{enumerate}
\end{multicols}

\item Consider a fixed effects two-way analysis of variance model
\begin{align*}
Y_{ijk} = \mu + \alpha_i + \beta_j + \gamma_{ij} + \epsilon_{ijk},
\end{align*}
where \(i=1,\ldots, a; j=1,\ldots,b; k=1,\ldots,r\), and the \(\epsilon_{ijk}\)'s are independent and identically distributed normal random variables with mean zero and constant variance. Then the degrees of freedom available to estimate the error variance is zero when:\\
\hspace*{15.7cm}(GATE ST 2019)
\begin{enumerate}
\item \(a=1\)
\item \(b=1\)
\item \(r=1\)
\item None of the above
\end{enumerate}



\item For \(k = 1, 2, \ldots, 10\), let the probability density function of the random variable \(X_k\) be
\begin{align*}
f_{X_k}(x) = \begin{cases}
\frac{e^{-x/k}}{k}, & x > 0 \\
0, & \text{otherwise}
\end{cases}
\end{align*}
Then \(E\left(\sum_{k=1}^{10} k X_k\right)\) is equal to \ldots \hfill(GATE ST 2019)

\item The probability density function of the random vector \((X, Y)\) is given by
\begin{align*}
f_{X,Y}(x,y) = \begin{cases}
c, & 0 < x < y < 1 \\
0, & \text{otherwise}
\end{cases}
\end{align*}
Then the value of \(c\) is equal to \ldots \hfill(GATE ST 2019)

\item Let \(\{X_n\}_{n \geq 1}\) be a sequence of independent and identically distributed normal random variables with mean 4 and variance 1. Then
\begin{align*}
\lim_{n \to \infty} P\left(\frac{1}{n} \sum_{i=1}^n X_i > 4.0006\right)
\end{align*}
is equal to \ldots \hfill(GATE ST 2019)

\item Let \((X_1, X_2)\) be a random vector following a bivariate normal distribution with mean vector \((0, 0)\), variances \(Var(X_1) = Var(X_2) = 1\), and correlation coefficient \(\rho\), where \(|\rho| < 1\). Then $P(X_1 + X_2 > 0)$ is equal to \ldots \hfill(GATE ST 2019)

\item Let \(X_1, \ldots, X_n\) be a random sample from a normal distribution with mean \(\mu\) and variance 1. Let \(\Phi\) be the cumulative distribution function of the standard normal distribution. Given \(\Phi(1.96) = 0.975\), the minimum sample size required such that the length of the 95\% confidence interval for \(\mu\) does NOT exceed 2 is \ldots \hfill(GATE ST 2019)

\item Let \(X\) be a random variable with probability density function
\begin{align*}
f(x; \theta) = \theta e^{-\theta x}, where  x \geq 0, \theta > 0.
\end{align*}
To test \(H_0: \theta = 1\) against \(H_1: \theta > 1\), the following test is used: \\
Reject \(H_0\) if and only if \(X > \log 20\). Then the size of the test is \ldots \hfill(GATE ST 2019)

\item Let \(\{X_n\}_{n \geq 0}\) be a discrete time Markov chain on the state space \(\{1,2,3\}\) with one-step transition probability matrix
\begin{align*}
\myvec{0.4 & 0.3 & 0.3 \\
0.5 & 0.2 & 0.3 \\
0.2 & 0.4 & 0.4}
\end{align*}
and initial distribution \(P(X_0 = 1) = 0.5, P(X_0 = 2) = 0.2, P(X_0 = 3) = 0.3\).
Then \(P(X_1 = 2, X_2 = 3, X_3 = 1)\) (rounded off to three decimal places) is equal to \ldots \hfill(GATE ST 2019)

\item Let \(f\) be a continuous and positive real-valued function on \([0,1]\). Then
\begin{align*}
\int_0^\pi f(\sin x) \cos x \, dx
\end{align*}
is equal to \ldots \hfill(GATE ST 2019)

\item A random sample of size 100 is classified into 10 class intervals covering all the data points. To test whether the data comes from a normal population with unknown mean and unknown variance, the chi-squared goodness of fit test is used. The degrees of freedom of the test statistic is equal to \ldots \hfill(GATE ST 2019)

\item For \(i = 1,2,3,4\), let \(Y_i = \alpha + \beta x_i + \epsilon_i\), where \(x_i\)'s are fixed covariates and \(\epsilon_i\)'s are uncorrelated random variables with mean 0 and variance 3. Here \(\alpha\) and \(\beta\) are unknown parameters. Given the observations: \ldots \hfill(GATE ST 2019)

\begin{tabular}{|c|c|c|c|c|}
\hline
$Y_i$ & 2 & 2.5 & -0.5 & 1 \\
\hline
$x_i$ & 3 & 2 & -4 & -1 \\
\hline
\end{tabular}\\
the variance of the least squares estimator of \(\beta\) is equal to 

\item Let \(a_n = \frac{(-1)^{n+1}}{n!}, n \geq 0\), and \(b_n = \sum_{k=0}^n a_k, n \geq 0\). Then, for \(|x| < 1\), the series
\begin{align*}
\sum_{n=0}^\infty b_n x^n
\end{align*}
converges to \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(-\frac{e^{-x}}{1+x}\)
\item \(-\frac{e^{-x}}{1-x^2}\)
\item \(-\frac{e^{-x}}{1-x}\)
\item \(- (1 + x) e^{-x}\)
\end{enumerate}
\end{multicols}

\item Let \(\{X_k\}_{k \geq 1}\) be a sequence of independent and identically distributed Bernoulli random variables with success probability \(p \in (0,1)\). Then, as \(n \to \infty\),
\begin{align*}
\frac{1}{n} \sum_{k=1}^n X_k
\end{align*}
converges almost surely to \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(p\)
\item \(\frac{1}{1-p}\)
\item \(\frac{1-p}{p}\)
\item \(1\)
\end{enumerate}
\end{multicols}

\item Let \(X\) and \(Y\) be two independent random variables with \(\chi^2_m\) and \(\chi^2_n\) distributions, respectively, where \(m\) and \(n\) are positive integers. Then which of the following statements is true? \hfill(GATE ST 2019)
\begin{enumerate}
\item For \(m < n\), \(P(X > a) \geq P(Y > a)\) for all \(a \in \mathbb{R}\).
\item For \(m > n\), \(P(X > a) \geq P(Y > a)\) for all \(a \in \mathbb{R}\).
\item For \(m < n\), \(P(X > a) = P(Y > a)\) for all \(a \in \mathbb{R}\).
\item None of the above.
\end{enumerate}

\item The matrix
\myvec{1 & x & z \\
0 & 2 & y \\
0 & 0 & 1}
is diagonalizable when \((x,y,z)\) equals \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \((0,0,1)\)
\item \((1,1,0)\)
\item \((\sqrt{2}, \sqrt{2}, 2)\)
\item \((\sqrt{2}, \sqrt{2}, \sqrt{2})\)
\end{enumerate}
\end{multicols}

\item Suppose that \(P_1\) and \(P_2\) are two populations with equal prior probabilities having bivariate normal distributions with mean vectors \((2,3)\) and \((1,1)\), respectively. The variance-covariance matrix of both the distributions is the identity matrix. Let \(z_1 = (2.5, 2)\) and \(z_2 = (2, 1.5)\) be two new observations. According to Fisher's linear discriminant rule: \hfill(GATE ST 2019)
\begin{enumerate}
\item \(z_1\) is assigned to \(P_1\), and \(z_2\) is assigned to \(P_2\).
\item \(z_1\) is assigned to \(P_2\), and \(z_2\) is assigned to \(P_1\).
\item \(z_1\) is assigned to \(P_1\), and \(z_2\) is assigned to \(P_1\).
\item \(z_1\) is assigned to \(P_2\), and \(z_2\) is assigned to \(P_2\).
\end{enumerate}



\item Let \(X_1, \ldots, X_n\) be a random sample from a population having probability density function
\begin{align*}
f_X(x; \theta) = \frac{2x}{\theta^2}, \quad 0 < x < \theta.
\end{align*}
Then the method of moments estimator of \(\theta\) is \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(\frac{3 \sum_{i=1}^n X_i}{2n}\)
\item \(\frac{3 \sum_{i=1}^n X_i^2}{2n}\)
\item \(\frac{\sum_{i=1}^n X_i}{n}\)
\item \(\frac{3 \sum_{i=1}^n X_i (X_i -1)}{2n}\)
\end{enumerate}
\end{multicols}

\item Let \(X\) be a normal random variable having mean \(\theta\) and variance 1, where \(1 \leq \theta \leq 10\). Then \(X\) is \hfill(GATE ST 2019)
\begin{enumerate}
\item sufficient but not complete
\item the maximum likelihood estimator of \(\theta\)
\item the uniformly minimum variance unbiased estimator of \(\theta\)
\item complete and ancillary
\end{enumerate}

\item Let \(\{X_n\}_{n\geq 1}\) be a sequence of independent and identically distributed random variables with mean \(\theta\) and variance \(\theta\), where \(\theta > 0\). Then
\begin{align*}
\frac{\sum_{i=1}^n X_i}{\sum_{i=1}^n X_i^2}
\end{align*}
is a consistent estimator of \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(\frac{1}{1+\theta}\)
\item \(\frac{1+\theta}{\theta}\)
\item \(\frac{1}{\theta}\)
\item \(\frac{\theta}{1+\theta}\)
\end{enumerate}
\end{multicols}

\item Let \(X_1, \ldots, X_{10}\) be a random sample from a population with probability density function
\begin{align*}
f(x;\theta) = e^{-|x - \theta|}/2, \quad -\infty < x < \infty, -\infty < \theta < \infty.
\end{align*}
Then the maximum likelihood estimator of \(\theta\) \hfill(GATE ST 2019)
\begin{enumerate}
\item does not exist
\item is not unique
\item is the sample mean
\item is the smallest observation
\end{enumerate}

\item Consider the model
\begin{align*}
Y_i = \beta + \epsilon_i,
\end{align*}
where \(\epsilon_i\)'s are independent normal random variables with zero mean and known variance \(\sigma_i^2 > 0\) for \(i=1, \ldots, n\). Then the best linear unbiased estimator of the unknown parameter \(\beta\) is \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(\frac{\sum_{i=1}^n \frac{Y_i}{\sigma_i^2}}{\sum_{i=1}^n \frac{1}{\sigma_i^2}}\)
\item \(\frac{\sum_{i=1}^n Y_i}{n}\)
\item \(\frac{\sum_{i=1}^n \frac{Y_i}{\sigma_i}}{n}\)
\item \(\frac{\sum_{i=1}^n \frac{Y_i}{\sigma_i}}{\sum_{i=1}^n \frac{1}{\sigma_i}}\)
\end{enumerate}
\end{multicols}

\item Let \((X, Y)\) be a bivariate random vector with probability density function
\begin{align*}
f_{X,Y}(x,y) = \begin{cases}
e^{-y}, & 0 < x < y \\
0, & \text{otherwise}
\end{cases}.
\end{align*}
Then the regression of \(Y\) on \(X\) is given by\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(X + 1\)
\item \(\frac{X}{2}\)
\item \(\frac{Y}{2}\)
\item \(Y + 1\)
\end{enumerate}
\end{multicols}

\item Consider a discrete time Markov chain on the state space \(\{1, 2\}\) with one-step transition probability matrix
\begin{align*}
P = \myvec{0.2 & 0.8 \\
0.3 & 0.7}.
\end{align*}
Then
\begin{align*}
\lim_{n \to \infty} P^n
\end{align*} is \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(\myvec{\frac{3}{11} & \frac{8}{11} \\ \frac{3}{11} & \frac{8}{11}}\)
\item \(\myvec{ 1 & 0 \\ 0 & 1}\)
\item \(\myvec{ 0 & 1 \\ 1 & 0 }\)
\item \(\myvec{ \frac{8}{11} & \frac{3}{11} \\ \frac{8}{11} & \frac{3}{11}}\)
\end{enumerate}
\end{multicols}

\item Let \((X_1, X_2)\) be a random vector with variance-covariance matrix
\begin{align*}
\myvec{
4 & 0 \\
0 & 2}.
\end{align*}
The two principal components are \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(X_1\) and \(X_2\)
\item \(-X_1\) and \(X_2\)
\item \(X_1\) and \(-X_2\)
\item \(X_1 + X_2\) and \(X_2\)
\end{enumerate}
\end{multicols}

\item Consider the objects \(\{1,2,3,4\}\) with the distance matrix
\begin{align*}
\myvec{0 & 1 & 11 & 5 \\
1 & 0 & 2 & 3 \\
11 & 2 & 0 & 4 \\
5 & 3 & 4 & 0}.
\end{align*}
Applying the single-linkage hierarchical procedure twice, the two clusters that result are\hfill(GATE ST 2019)
\begin{multicols}{2}
\begin{enumerate}
\item \(\{2,3\}\) and \(\{1,4\}\)
\item \(\{1,2,3\}\) and \(\{4\}\)
\item \(\{1,3,4\}\) and \(\{2\}\)
\item \(\{2,3,4\}\) and \(\{1\}\)
\end{enumerate}
\end{multicols}

\item The maximum likelihood estimates of the mean vector and the variance-covariance matrix of a bivariate normal distribution based on the realization \(\myvec{1 \\ 2},\myvec{4 \\ 4},\myvec{4 \\ 3}\) of a random sample of size 3, are given by\hfill(GATE ST 2019)
\begin{multicols}{2}
\begin{enumerate}
\item \((3,3)\) and \(\myvec { 2 & 1 \\ 1 & \frac{2}{3}}\)
\item \((3,3)\) and \(\myvec{ 2 & 1 \\ 1 & \frac{3}{2}}\)
\item \((3,3)\) and \(\myvec{ 3 & \frac{3}{2} \\ \frac{3}{2} & \frac{2}{3}}\)
\item \((3,3)\) and \(\myvec{ 3 & \frac{2}{3} \\ \frac{2}{3} & 1}\)
\end{enumerate}
\end{multicols}

\item Consider a fixed effects one-way analysis of variance model
\begin{align*}
Y_{ij} = \mu + \tau_i + \epsilon_{ij},
\end{align*}
for \(i=1,\ldots,a; j=1,\ldots,r\), where the \(\epsilon_{ij}\) are independent and identically distributed normal random variables with mean zero and variance \(\sigma^2\).Here,r and a are positive integers.Let
\begin{align*}
\bar{Y}_{i \cdot} = \frac{1}{r} \sum_{j=1}^r Y_{ij}.
\end{align*}
Then \(\bar{Y}_{i \cdot}\) is the least squares estimator for\hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(\mu +\frac{\tau_i}{2}\)
\item \(\tau_i\)
\item \(\mu + \tau_i\)
\item \(\mu\)
\end{enumerate}
\end{multicols}


\item Let \(A\) be an \(n \times n\) positive semi-definite matrix with eigenvalues \(\lambda_1 \geq \cdots \geq \lambda_n\), and with \(\alpha\) as the maximum diagonal entry. We can find a vector \(x\) such that \(x^t x = 1\), where \(t\) denotes transpose, and \hfill(GATE ST 2019)
\begin{enumerate}
\item \(x^t A x > \lambda_1\)
\item \(x^t A x < \lambda_n\)
\item \(\lambda_n \leq x^t A x \leq \lambda_1\)
\item \(x^t A x > n \alpha\)
\end{enumerate}

\item Let \(X\) be a random variable with uniform distribution on the interval \((-1,1)\) and let \(Y = (X+1)^2\). Then the probability density function \(f(y)\) of \(Y\), over the interval \((0,4)\), is \hfill(GATE ST 2019)
\begin{multicols}{4}
\begin{enumerate}
\item \(\frac{3\sqrt{y}}{16}\)
\item \(\frac{1}{4\sqrt{y}}\)
\item \(\frac{1}{6\sqrt{y}}\)
\item \(\frac{1}{\sqrt{y}}\)
\end{enumerate}
\end{multicols}

\item Let \(S\) be the solid whose base is the region in the \(xy\)-plane bounded by the curves
\begin{align*}
y = x^2 \quad \text{and} \quad y = 8 - x^2,
\end{align*}
and whose cross-sections perpendicular to the \(x\)-axis are squares. Then the volume of \(S\) (rounded off to two decimal places) is \ldots \hfill(GATE ST 2019)

\item Consider the trinomial distribution with the probability mass function
\begin{align*}
P(X = x, Y= y) = \frac{7!}{x! y! (7 - x - y)!} (0.6)^x (0.2)^y (0.2)^{7 - x - y},
\end{align*} and \(x \geq 0, y \geq 0\), and \(x + y \leq 7\).
Then \(E(Y \mid X = 3)\) is equal to \ldots \hfill(GATE ST 2019)

\item Let \(Y_i = \alpha + \beta x_i + \epsilon_i\), where \(i = 1, 2, 3, 4\), \(x_i\)'s are fixed covariates and \(\epsilon_i\)'s are independent and identically distributed standard normal random variables. Here \(\alpha\) and \(\beta\) are unknown parameters. Let \(\Phi\) be the cumulative distribution function of the standard normal distribution and \(\Phi(1.96) = 0.975\). Given the following observations: \\
\begin{tabular}{|c|c|c|c|c|}
\hline
$Y_i$ & 2 & 2.5 & -0.5 & 1 \\
\hline
$x_i$ & 3 & 2 & -4 & -1 \\
\hline
\end{tabular}\\
The length (rounded off to two decimal places) of the shortest 95\% confidence interval for \(\beta\) based on its least squares estimator is equal to \ldots \hfill(GATE ST 2019)

\item Consider a discrete time Markov chain on the state space \(\{1,2,3\}\) with one-step transition probability matrix
\myvec{0 & 0.2 & 0.8 \\
0.5 & 0 & 0.5 \\
0.6 & 0.4 & 0 }.
Then the period of the Markov chain is \ldots \hfill(GATE ST 2019)

\item Suppose customers arrive at an ATM facility according to a Poisson process with rate 5 customers per hour. The probability (rounded off to two decimal places) that no customer arrives at the ATM facility from 1:00 pm to 1:18 pm is \ldots \hfill(GATE ST 2019)

\item Let \(X\) be a random variable with characteristic function \(\phi_X(\cdot)\) such that \(\phi_X(2 \pi) = 1\). Let \(\mathbb{Z}\) denote the set of integers. Then \(P(X \in \mathbb{Z})\) is equal to \ldots \hfill(GATE ST 2019)

\item Let \(X_1\) be a random sample of size 1 from uniform distribution over \((\theta, \theta^2)\), where \(\theta > 1\). To test \(H_0: \theta = 2\) against \(H_1: \theta = 3\), reject \(H_0\) if and only if \(X_1 > 3.5\). Let \(\alpha\) and \(\beta\) be the size and the power, respectively, of this test. Then \(\alpha + \beta\) (rounded off to two decimal places) is equal to \ldots \hfill(GATE ST 2019)

\item Let \(Y_i = \beta_0 + \beta_1 x_i + \epsilon_i, i=1, \ldots, n\), where \(x_i\)'s are fixed covariates and \(\epsilon_i\)'s are uncorrelated random variables with mean zero and constant variance. Suppose that \(\hat{\beta}_0\) and \(\hat{\beta}_1\) are the least squares estimators of the unknown parameters \(\beta_0\) and \(\beta_1\), respectively. If \(\sum_{i=1}^n x_i = 0\), then the correlation between \(\hat{\beta}_0\) and \(\hat{\beta}_1\) is equal to \ldots \hfill(GATE ST 2019)

\item Let \(f : \mathbb{R} \to \mathbb{R}\) be defined by
\begin{align*}
f(x) = (3x^2 + 4) \cos x. 
\end{align*}
Then \hfill(GATE ST 2019)
\begin{align*}
\lim_{h \to 0} \frac{f(h) + f(-h) - 8}{h^2}
\end{align*}
is equal to \ldots 

\item The maximum value of \((x - 1)^2 + (y - 2)^2\) subject to the constraint \(x^2 + y^2 \leq 45\) is equal to \ldots \hfill(GATE ST 2019)

\item Let \(X_1, \ldots, X_{10}\) be independent and identically distributed normal random variables with mean 0 and variance 2. Then $E\left(\frac{X_1^2}{X_1^2 + \cdots + X_{10}^2}\right)$

is equal to \ldots \hfill(GATE ST 2019)

\item Let \(I\) be the \(4 \times 4\) identity matrix and \(v = (1, 2, 3, 4)^t\), where \(t\) denotes transpose. Then the determinant of I + v $v^t$
is equal to \ldots \hfill(GATE ST 2019)


\end{enumerate}






\end{document}